{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    This jupyter notebook generates the partial dependence plots in the paper.\n",
    "\n",
    "    This includes: Figures 8, 9, 10, and 11\n",
    "\n",
    "\n",
    "    Note: This file requires installing the causalml package. Because the T-Learner in the EconML library does not offer an implementation that computes feature importance, the CausalML was used for this purpose. \n",
    "    However, due to installation issues and conflicts with Conda, the library was installed from the source where a new virtual environment was created. This created the issue\n",
    "    of conflicting environments as all other scripts utilized another virtual environment with a more current Python version. \n",
    "    To circumvent this problem, all the simulated data generated above is saved in a .pkl file. Then, in the 'TLearner_feat_imp.py' file, the simulated data .kl files were \n",
    "    unpacked and the T-Learner was estimated. The results are finally saved in a .npy file. \n",
    "\n",
    "    Since TLearner_feat_imp.py runs in another environment, the subprocess package was used to reconcile both virtual environments.\n",
    "\n",
    "    Make sure to provide the correct environment where the CausalML package is installed so that the program can run properly. \n",
    "    \n",
    "    See https://causalml.readthedocs.io/en/latest/installation.html to install the library and https://github.com/uber/causalml/issues/678 to troubleshoot potential installation\n",
    "    issues. \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Gen_data import SimulationStudy\n",
    "import Methods_all_sample as method\n",
    "from Analysis_new import get_split\n",
    "import subprocess\n",
    "import pickle\n",
    "import feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save  to a pkl file as to ensure that both EconML methods and the causalml T-learner utilize the same data\n",
    "def save_to_pkl(data_name, data):\n",
    "    with open(f'{data_name}.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(data, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate simulation and split into train and test\n",
    "def get_sim(function: str) -> tuple[dict]:    \n",
    "    sim: SimulationStudy = SimulationStudy(p=35, mean_correlation=0.5, cor_variance=0.2, n=4000, no_feat_cate=3, non_linear = function, seed=220924)\n",
    "    simulation = sim.create_dataset()\n",
    "    train_df, test_df, X_train, Y_train, T_train, X_test, T_test, Y_test, true_cate_train, true_cate_test = get_split(simulation)\n",
    "\n",
    "    df_dict_TLearner = {'train_df': train_df, 'X_train': X_train, 'Y_train': Y_train, 'T_train': T_train, 'X_test': X_test, 'T_test': T_test}\n",
    "\n",
    "    df_dict = {'Y_train': Y_train, 'T_train': T_train, 'X_train': X_train, 'X_test': X_test, 'T_test': T_test, 'true_cate_train': true_cate_train, 'true_cate_test': true_cate_test}\n",
    "\n",
    "    return df_dict_TLearner, df_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the simulation and pass it to the save_to_pkl function\n",
    "def save_simulation(sim_type: str):\n",
    "    for data_name, data in sim_type.items():\n",
    "        save_to_pkl(data_name, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the necessary data from the dictionary\n",
    "def get_data(dict:dict) -> tuple[dict]:\n",
    "    return  dict['Y_train'], dict['T_train'], dict['X_train'], dict['X_test'], dict['T_test'], dict['true_cate_train'], dict['true_cate_test'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the T_learner_feat_imp.py in the correct environment\n",
    "def run_TLearner_causalml(env = r'C:\\Users\\joaov\\anaconda3\\envs\\causalml-py38\\python.exe'):\n",
    "    subprocess.run([env, 'TLearner_feat_imp.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the partial dependence plots from each estimator\n",
    "def get_plots(data_dict: dict, estimator, setting: str):\n",
    "\n",
    "    Y_train, T_train, X_train, X_test, T_test, true_cate_train, true_cate_test = get_data(data_dict)\n",
    "    \n",
    "    if estimator == 'T-Learner':\n",
    "        est, estimated_cate_train, estimated_cate_test, RMSE_test, RMSE_train = method.TLearner_estimator(Y_train, T_train, X_train, X_test, T_test, \n",
    "                                                                                                    true_cate_train, true_cate_test)\n",
    "        \n",
    "        important_feats_t = np.load('feat_importance_TLearner.npy', allow_pickle=True)\n",
    "        feats_dict = important_feats_t.item()\n",
    "        series = feats_dict[1]\n",
    "        feat_importance = series.index\n",
    "\n",
    "        feature_importance.partial_dependence_plots_ML(X_test, feat_importance, est = est, setting=setting)\n",
    "              \n",
    "    elif estimator == 'GRF':\n",
    "        est, feat_importance, estimated_cate_train, estimated_cate_test, RMSE_test, RMSE_train = method.GRF_estimator(Y_train, T_train, X_train, X_test, T_test, \n",
    "                                                                                                                      true_cate_train, true_cate_test)\n",
    "        \n",
    "        important_feats_grf = feature_importance.get_important_feats(X_test, feat_importance)\n",
    "        feature_importance.partial_dependence_plots_ML(X_test, important_feats_grf, est = est, setting=setting)\n",
    "        \n",
    "    elif estimator == 'CF DML':\n",
    "        est, feat_importance, estimated_cate_train, estimated_cate_test, RMSE_test, RMSE_train = method.CF_DML(Y_train, T_train, X_train, X_test, T_test, \n",
    "                                                                                                    true_cate_train, true_cate_test)\n",
    "        \n",
    "        important_feats_cfdml = feature_importance.get_important_feats(X_test, feat_importance)\n",
    "        feature_importance.partial_dependence_plots_ML(X_test, important_feats_cfdml, est = est, setting=setting)\n",
    "    \n",
    "    else:\n",
    "        conf_int, coeff, estimated_cate_ols_train, estimated_cate_ols_test, OLS_RMSE_train, OLS_RMSE_test = method.ols_estimator(Y_train=Y_train, T_train=T_train, X_train=X_train, X_test=X_test, \n",
    "                                                                                                                                 T_test=T_test, true_cate_train=true_cate_train, true_cate_test=true_cate_test, ci=True)\n",
    "        \n",
    "        \n",
    "        feature_importance.plot_OLS(X_test, coeff, conf_int, setting=setting)\n",
    "        \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(220924)\n",
    "df_linear_T, sim_lin = get_sim('linear')\n",
    "save_simulation(df_linear_T)\n",
    "run_TLearner_causalml() #make sure to set env=path where the causalml package is installed\n",
    "get_plots(sim_lin, 'OLS', setting='linear')\n",
    "get_plots(sim_lin, 'T-Learner', setting='linear')\n",
    "get_plots(sim_lin, 'GRF', setting='linear')\n",
    "get_plots(sim_lin, 'CF DML', setting='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadratic Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(220924)\n",
    "df_quadratic_T, sim_quad = get_sim('quadratic')\n",
    "save_simulation(df_quadratic_T)\n",
    "run_TLearner_causalml() #make sure to set env=path where the causalml package is installed\n",
    "get_plots(sim_quad, 'OLS', setting='quadratic')\n",
    "get_plots(sim_quad, 'T-Learner', setting='quadratic')\n",
    "get_plots(sim_quad, 'GRF', setting='quadratic')\n",
    "get_plots(sim_quad, 'CF DML', setting='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that both libraries deliver the exact same CATEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cate_t_causalml= np.load('causalml_cate_tlearner.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8, 6))\n",
    "#plt.hist([estimated_cate_test, cate_t_causalml.reshape(1,-1).flatten()], bins=30, alpha=0.5, label=['Econ ML', 'CausalML'])\n",
    "#plt.xlabel('CATE Estimates')\n",
    "#plt.ylabel('Frequency')\n",
    "#plt.title('Overlap of CATE Estimates from EconML and CausalML')\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalml-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
